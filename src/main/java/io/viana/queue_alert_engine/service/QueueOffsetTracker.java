package io.viana.queue_alert_engine.service;

import io.viana.queue_alert_engine.config.AlertsProperties;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.ListConsumerGroupOffsetsResult;
import org.apache.kafka.common.TopicPartition;
import org.springframework.stereotype.Service;

import jakarta.annotation.PostConstruct;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;
import java.util.stream.Collectors;

/**
 * Servi√ßo respons√°vel por rastrear e manter o √∫ltimo offset (posi√ß√£o)
 * consumido por cada grupo de consumidores Kafka.
 */
@Slf4j // Para logging
@Service // Marca a classe como um servi√ßo Spring
@RequiredArgsConstructor // Cria o construtor necess√°rio para inje√ß√£o de depend√™ncia
public class QueueOffsetTracker {

    // Configura√ß√µes dos alertas, incluindo quais grupos e parti√ß√µes monitorar
    private final AlertsProperties alertsProperties;
    // Cliente administrativo do Kafka, usado para buscar informa√ß√µes como offsets
    private final AdminClient adminClient;

    // Mapa para armazenar as parti√ß√µes que precisam ser monitoradas para cada grupo
    // Chave: GroupId | Valor: Lista de TopicPartition (t√≥pico e parti√ß√£o)
    private final Map<String, List<TopicPartition>> monitoredPartitions = new ConcurrentHashMap<>();
    // Mapa para armazenar o √∫ltimo offset consumido.
    // Chave Externa: GroupId | Chave Interna: TopicPartition | Valor Interno: Offset (posi√ß√£o)
    private final Map<String, Map<TopicPartition, Long>> consumedOffsets = new ConcurrentHashMap<>();

    /**
     * Inicializa o servi√ßo ap√≥s a constru√ß√£o do objeto.
     * Carrega as parti√ß√µes a serem monitoradas a partir das configura√ß√µes.
     */
    @PostConstruct
    public void init() {
        // Percorre todos os grupos configurados
        alertsProperties.getGroups().forEach(group -> {

            String groupId = group.getGroupId();

            // Mapeia as regras de alerta para objetos TopicPartition
            List<TopicPartition> partitions = group.getRules().stream()
                    .map(r -> new TopicPartition(r.topic(), r.partition()))
                    .collect(Collectors.toList());

            // Armazena as parti√ß√µes que ser√£o monitoradas para este grupo
            monitoredPartitions.put(groupId, partitions);
            // Inicializa o mapa de offsets consumidos para este grupo
            consumedOffsets.put(groupId, new ConcurrentHashMap<>());

            log.info("üìù Grupo monitorado: {}", groupId);
            log.info("üìù Parti√ß√µes monitoradas: {}", partitions);
        });

        // Chama a atualiza√ß√£o inicial de offsets para todos os grupos
        alertsProperties.getGroups()
                .forEach(g -> updateConsumedOffsets(g.getGroupId()));
    }

    /**
     * Busca no Kafka e atualiza os √∫ltimos offsets consumidos para um grupo espec√≠fico.
     *
     * @param groupId O ID do grupo de consumidores a ser verificado.
     */
    public void updateConsumedOffsets(String groupId) {
        try {
            // Solicita ao AdminClient os offsets consumidos pelo grupo
            ListConsumerGroupOffsetsResult result = adminClient.listConsumerGroupOffsets(groupId);

            // Processa o resultado e cria um mapa simplificado (TopicPartition -> Offset)
            Map<TopicPartition, Long> offsets = result.partitionsToOffsetAndMetadata().get()
                    .entrySet()
                    .stream()
                    .collect(Collectors.toMap(
                            Map.Entry::getKey,
                            e -> e.getValue().offset() // Extrai apenas o valor do offset
                    ));

            // Pega o mapa de offsets que pertence a este grupo
            Map<TopicPartition, Long> groupOffsets = consumedOffsets.get(groupId);

            // Itera sobre as parti√ß√µes monitoradas e armazena o offset encontrado
            monitoredPartitions.getOrDefault(groupId, List.of())
                    .forEach(tp -> groupOffsets.put(tp, offsets.getOrDefault(tp, 0L))); // Se n√£o encontrar, usa 0

            log.debug("üîé Offsets atualizados para group {} ‚Üí {}", groupId, groupOffsets);

        } catch (Exception e) {
            log.error("‚ùå Erro ao atualizar offsets consumidos para group {}: {}", groupId, e.getMessage(), e);
        }
    }

    /**
     * Retorna o √∫ltimo offset consumido conhecido para uma dada parti√ß√£o e grupo.
     *
     * @param groupId O ID do grupo de consumidores.
     * @param topic O nome do t√≥pico.
     * @param partition O n√∫mero da parti√ß√£o.
     * @return O √∫ltimo offset consumido, ou 0 se n√£o for encontrado.
     */
    public long getLastConsumedOffset(String groupId, String topic, int partition) {
        Map<TopicPartition, Long> groupOffsets = consumedOffsets.get(groupId);
        if (groupOffsets == null) return 0; // Grupo n√£o monitorado

        // Retorna o offset da parti√ß√£o espec√≠fica, ou 0 se n√£o houver
        return groupOffsets.getOrDefault(new TopicPartition(topic, partition), 0L);
    }

    /**
     * Getter necess√°rio para o MonitorController.
     *
     * @return O mapa completo de offsets consumidos por todos os grupos.
     */
    public Map<String, Map<TopicPartition, Long>> getConsumedOffsets() {
        return consumedOffsets;
    }
}